{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["YeieIjfTlhEL"],"gpuType":"T4","authorship_tag":"ABX9TyMWNLyFEzYh1iv9VgyOVj0e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew-_S9D5asWl","outputId":"906cbff8-9d5f-45f1-869a-b1c33461bc02","executionInfo":{"status":"ok","timestamp":1685352660012,"user_tz":-540,"elapsed":27384,"user":{"displayName":"나상우","userId":"01186409037967778319"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# 모델 구현"],"metadata":{"id":"ZR45ueG8lmRU"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import os"],"metadata":{"id":"VUR4hJgYlsXf","executionInfo":{"status":"ok","timestamp":1685352664101,"user_tz":-540,"elapsed":4097,"user":{"displayName":"나상우","userId":"01186409037967778319"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_project\n","path = os.getcwd()\n","train_path = path + '/data/' + 'train.txt'\n","valid_path = path + '/data/' + 'valid.txt'\n","test_path = path  + '/data/' + 'test.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LemXyC_Al7we","executionInfo":{"status":"ok","timestamp":1685352664102,"user_tz":-540,"elapsed":10,"user":{"displayName":"나상우","userId":"01186409037967778319"}},"outputId":"b458ba64-9046-4015-8d07-4ff7307b5a74"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_project\n"]}]},{"cell_type":"code","source":["#!pip install transformers\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.preprocessing import LabelEncoder\n"],"metadata":{"id":"LnpAAcec3MQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, tokenizer, sentences, labels, max_len):\n","        self.tokenizer = tokenizer\n","        self.sentences = sentences\n","        self.labels = labels\n","        self.max_len = max_len\n","    \n","    def __len__(self):\n","        return len(self.sentences)\n","    \n","    def __getitem__(self, item):\n","        encoding = self.tokenizer.encode_plus(\n","            self.sentences[item],\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","        return {\n","            'text': self.sentences[item],\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(self.labels[item], dtype=torch.long)\n","        }\n","\n","def load_data(file_path, label_encoder=None):\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        lines = f.readlines()\n","        labels = []\n","        sentences = []\n","        for i, data in enumerate(lines):\n","          if i< 2:\n","            continue\n","          if data == '\\n':\n","            continue\n","          ID, speaker, utt, ethics_types, immoral = data.strip().split('\\t')\n","          sentences.append(utt)\n","          labels.append(ethics_types)\n","    if label_encoder is None:\n","        label_encoder = LabelEncoder()\n","        labels = label_encoder.fit_transform(labels)\n","    else:\n","        labels = label_encoder.transform(labels)\n","    return sentences, labels, label_encoder"],"metadata":{"id":"w5u-_P293NGg","executionInfo":{"status":"ok","timestamp":1685353287033,"user_tz":-540,"elapsed":6,"user":{"displayName":"나상우","userId":"01186409037967778319"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","epochs = 10\n","batch_size = 16\n","max_len = 128\n","learning_rate = 1e-5\n"],"metadata":{"id":"HtTID8Oh44NH","executionInfo":{"status":"ok","timestamp":1685353558525,"user_tz":-540,"elapsed":4,"user":{"displayName":"나상우","userId":"01186409037967778319"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Model & Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base-v2022\", num_labels=8)\n","\n","# Load data & Dataset & DataLoader\n","train_sentences, train_labels, label_encoder = load_data(train_path)\n","val_sentences, val_labels, _ = load_data(valid_path, label_encoder)\n","test_sentences, test_labels, _ = load_data(test_path, label_encoder)\n","\n","train_dataset = CustomDataset(tokenizer, train_sentences, train_labels, max_len)\n","val_dataset = CustomDataset(tokenizer, val_sentences, val_labels, max_len)\n","test_dataset = CustomDataset(tokenizer, test_sentences, test_labels, max_len)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","# Optimizer\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","\n","# Device\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7DxlRP75Tzx","executionInfo":{"status":"ok","timestamp":1685353576554,"user_tz":-540,"elapsed":5401,"user":{"displayName":"나상우","userId":"01186409037967778319"}},"outputId":"9cc93154-3e25-46c1-b24f-53954f4216ea"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=8, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        \n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","    \n","    model.eval()\n","    val_predictions = []\n","    val_true_labels = []\n","    for batch in val_loader:\n","        with torch.no_grad():\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            val_predictions.extend(torch.argmax(outputs.logits, dim=1).tolist())\n","            val_true_labels.extend(labels.tolist())\n","    \n","    # Metrics\n","    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n","    val_precision, val_recall, val_fscore, _ = precision_recall_fscore_support(val_true_labels, val_predictions, average='weighted')\n","    print(f'Epoch {epoch+1}/{epochs} | Val Accuracy: {val_accuracy:.2f} | Val Precision: {val_precision:.2f} | Val Recall: {val_recall:.2f} | Val F-score: {val_fscore:.2f}')\n","\n","# Testing\n","test_predictions = []\n","test_true_labels = []\n","for batch in test_loader:\n","    with torch.no_grad():\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        \n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        test_predictions.extend(torch.argmax(outputs.logits, dim=1).tolist())\n","        test_true_labels.extend(labels.tolist())\n","\n","# Metrics\n","test_accuracy = accuracy_score(test_true_labels, test_predictions)\n","test_precision, test_recall, test_fscore, _ = precision_recall_fscore_support(test_true_labels, test_predictions, average='weighted')\n","print(f'Test Accuracy: {test_accuracy:.2f} | Test Precision: {test_precision:.2f} | Test Recall: {test_recall:.2f} | Test F-score: {test_fscore:.2f}')\n","\n","# Save the model\n","model.save_pretrained('path_to_save_directory')\n"],"metadata":{"id":"AGhEwTzlz8p1"},"execution_count":null,"outputs":[]}]}