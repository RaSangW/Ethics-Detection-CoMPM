{"cells":[{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16394,"status":"ok","timestamp":1685345632449,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"prAcC0OrSj1V","outputId":"398aefad-dbbd-4f9b-c352-01eab01865a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1685345632450,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"c-0s0UtlSlpb","outputId":"ab390414-0f9b-4243-8355-a1e7b08bb400"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/NLP_project\n"]}],"source":["%cd /content/drive/MyDrive/NLP_project"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685345632450,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"cUCr2WUrSoaP"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import os"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685345632450,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"KvcP7r5jSvtd"},"outputs":[],"source":["path = os.getcwd()\n","\n","train_path = path + '/data/' + 'train.txt'\n","valid_path = path + '/data/' + 'valid.txt'\n","test_path = path  + '/data/' + 'test.txt'"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685345632450,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"S60ikb3dSyzG"},"outputs":[],"source":["\"\"\"Dataset Loading\"\"\"\n","dataclass = \"types\"\n","batch_size = 16\n","sample = 1.0\n","\n","num_workers = 2\n","\n","clsNum = 8"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PmTerQ9h1yNE"},"source":["## utils"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685345632451,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"Xkc6kddJZDvu"},"outputs":[],"source":["def encode_right_truncated(text, tokenizer, max_length=300):\n","    tokenized = tokenizer.tokenize(text, max_length = max_length, truncation=True)\n","    truncated = tokenized[-max_length:]\n","    ids = tokenizer.convert_tokens_to_ids(truncated)\n","    \n","    return [tokenizer.cls_token_id] + ids"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685345632451,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"XilCGSv3ZAT6"},"outputs":[],"source":["def padding(ids_list, tokenizer):\n","    max_len = 0\n","    for ids in ids_list:\n","        if len(ids) > max_len:\n","            max_len = len(ids)\n","    \n","    pad_ids = []\n","    for ids in ids_list:\n","        pad_len = max_len-len(ids)\n","        add_ids = [tokenizer.pad_token_id for _ in range(pad_len)]\n","        \n","        pad_ids.append(ids+add_ids)\n","    \n","    return torch.tensor(pad_ids)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685345632451,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"fyNixJeoZfx9"},"outputs":[],"source":["def Make_batch(sessions):\n","    batch_input, batch_labels = [], []\n","    for session in sessions:\n","        data = session[0]\n","        label_list = session[1]\n","        \n","        context_speaker, utt, ethics_types, immoral = data\n","        now_speaker = context_speaker[-1]\n","        speaker_utt_list = []\n","\n","        inputString = \"\"\n","        for turn, (speaker, utt) in enumerate(zip(context_speaker, utt)):\n","            inputString += '<s' + str(speaker+1) + '> ' # s1, s2, s3...\n","            inputString += utt + \" \"\n","\n","            if turn<len(context_speaker)-1 and speaker == now_speaker:\n","                speaker_utt_list.append(encode_right_truncated(utt, KcELECTRA_tokenizer, max_length=511))\n","        \n","        concat_string = inputString.strip()\n","        batch_input.append(encode_right_truncated(concat_string, KcELECTRA_tokenizer, max_length=511))\n","        \n","        if len(label_list) > 3:\n","            label_ind = label_list.index(ethics_types)\n","        else:\n","            label_ind = label_list.index(immoral)\n","        batch_labels.append(label_ind)        \n","        \n","        \n","    \n","    batch_input_tokens = padding(batch_input, KcELECTRA_tokenizer)\n","    batch_labels = torch.tensor(batch_labels)\n","\n","    if len(batch_input_tokens) > 512:\n","      batch_input_tokens = batch_input_tokens[:512]\n","    \n","    return batch_input_tokens, batch_labels"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685345632451,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"GWgk0Sv8eZzb"},"outputs":[],"source":["def CELoss(pred_outs, labels):\n","    \"\"\"\n","        pred_outs: [batch, clsNum]\n","        labels: [batch]\n","    \"\"\"\n","    loss = nn.CrossEntropyLoss()\n","    loss_val = loss(pred_outs, labels)\n","    return loss_val"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685345632451,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"qqs4qyRbZIqR"},"outputs":[],"source":["def _CalACC(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    label_list = []\n","    pred_list = []\n","    \n","    # label arragne\n","    with torch.no_grad():\n","        for i_batch, data in enumerate(dataloader):            \n","            \"\"\"Prediction\"\"\"\n","            batch_input_tokens, batch_labels = data\n","            batch_input_tokens, batch_labels = batch_input_tokens.cuda(), batch_labels.cuda()\n","            \n","            pred_logits = model(batch_input_tokens) # (1, clsNum)\n","            \n","            \"\"\"Calculation\"\"\"    \n","            pred_label = pred_logits.argmax(1).item()\n","            true_label = batch_labels.item()\n","            \n","            pred_list.append(pred_label)\n","            label_list.append(true_label)\n","            if pred_label == true_label:\n","                correct += 1\n","        acc = correct/len(dataloader)\n","    return acc, pred_list, label_list"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685345632452,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"jSYYIuioZMGm"},"outputs":[],"source":["def _SaveModel(model, path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","    torch.save(model.state_dict(), os.path.join(path, 'model.pt'))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8X6MIWCj13k1"},"source":["## Model"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4883,"status":"ok","timestamp":1685345637328,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"wib1I-SsS1Ay","outputId":"e1f76cf6-ceee-411b-8b32-81292e2ea5f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1707,"status":"ok","timestamp":1685345639028,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"A2q0kLtGTqw2","outputId":"2fda121b-912c-4b0d-ad62-77f137c147f8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# KcBERT\n","#from transformers import AutoTokenizer, AutoModelWithLMHead\n","#KcBERT_model = AutoModelWithLMHead.from_pretrained(\"beomi/kcbert-base\")\n","#KcBERT_tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")\n","\n","# KcELECTRA\n","from transformers import AutoModel, AutoTokenizer\n","KcELECTRA_model = AutoModel.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n","KcELECTRA_tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685345639028,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"qwCP2Hg9KnB9"},"outputs":[],"source":["class ERC_model(nn.Module):\n","    def __init__(self, clsNum):\n","        super(ERC_model, self).__init__()\n","        self.gpu = True\n","        \n","        \"\"\"Model Setting\"\"\"\n","        # KcELECTRA\n","        self.model = KcELECTRA_model\n","        tokenizer = KcELECTRA_tokenizer\n","\n","        tokenizer.add_special_tokens({'cls_token': '[CLS]', 'pad_token': '[PAD]'})\n","        self.model.resize_token_embeddings(len(tokenizer))\n","        self.hiddenDim = self.model.config.hidden_size\n","        \n","\n","        \"\"\"score\"\"\"\n","        self.W = nn.Linear(self.hiddenDim, clsNum)\n","\n","        \n","\n","    def forward(self, batch_input_tokens):\n","        \"\"\"\n","            batch_input_tokens: (batch, len)\n","        \"\"\"\n","        \n","        batch_context_output = self.model(batch_input_tokens).last_hidden_state[:,0,:]\n","        context_logit = self.W(batch_context_output) # (batch, clsNum)\n","        \n","        return context_logit\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685345639028,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"aUWS7Ke0Y7_W"},"outputs":[],"source":["class KoEthcis_loader(Dataset):\n","    def __init__(self, txt_file, dataclass):\n","        self.dialogs = []\n","\n","        f = open(txt_file, 'r', encoding = \"utf-8\")\n","        dataset = f.readlines()\n","        f.close()\n","\n","        temp_speakerList = []\n","        context = []\n","        context_speaker = []\n","        self.speakerNum = []\n","        \n","        types_dict = {\n","            \"['CENSURE']\":'CENSURE', \"['HATE']\":'HATE',\n","            \"['DISCRIMINATION']\":'DISCRIMINATION', \"['SEXUAL']\":'SEXUAL',\n","            \"['ABUSE']\":'ABUSE', \"['VIOLENCE']\":'VIOLENCE',\n","            \"['CRIME']\":'CRIME', \"['IMMORAL_NONE']\":'IMMORAL_NONE'}\n","        self.immoral_dict = {\n","            'True': ['CENSURE', 'HATE', 'DISCRIMINATION',\n","                     'SEXUAL', 'ABUSE', 'VIOLENCE', 'CRIME'],\n","            'False': ['IMMORAL_NONE']}\n","\n","        self.typesSet = set(types_dict.values())\n","        self.immoralSet = set()\n","\n","        for i, data in enumerate(dataset):\n","            if i < 2:\n","                continue\n","            if data == '\\n' and len(self.dialogs) > 0:\n","                self.speakerNum.append(len(temp_speakerList))\n","                temp_speakerList = []\n","                context = []\n","                context_speaker = []\n","                continue\n","          \n","            ID, speaker, utt, ethics_types, immoral = data.strip().split('\\t')\n","            context.append(utt)\n","            if speaker not in temp_speakerList:\n","                temp_speakerList.append(speaker)\n","            speakerCLS = temp_speakerList.index(speaker)\n","            context_speaker.append(speakerCLS)\n","\n","            self.dialogs.append([context_speaker[:], context[:], types_dict[ethics_types], immoral])\n","            self.typesSet.add(types_dict[ethics_types])\n","            self.immoralSet.add(immoral)\n","\n","        self.typesList = sorted(self.typesSet)\n","        self.immoralList = sorted(self.immoralSet)\n","\n","        if dataclass == 'types':\n","            self.labelList = self.typesList\n","        else:\n","            self.labelList = self.immoralList        \n","        self.speakerNum.append(len(temp_speakerList))\n","        \n","    def __len__(self):\n","        return len(self.dialogs)\n","\n","    def __getitem__(self, idx):\n","        return self.dialogs[idx], self.labelList, self.immoralList"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":1252,"status":"ok","timestamp":1685345640278,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"aXfUOiRVbf8S"},"outputs":[],"source":["model = ERC_model(clsNum)\n","model = model.cuda()\n","model.train()\n","\n","train_dataset = KoEthcis_loader(train_path, dataclass)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=Make_batch)\n","train_sample_num = int(len(train_dataset)*sample)\n","\n","test_dataset = KoEthcis_loader(test_path, dataclass)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=num_workers, collate_fn=Make_batch)\n","\n","valid_dataset = KoEthcis_loader(valid_path, dataclass)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=num_workers, collate_fn=Make_batch)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VidjHCV3eVsr"},"source":["## Train"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":2371,"status":"ok","timestamp":1685345642644,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"I73dMjzjdxoF"},"outputs":[],"source":["\"\"\"Training Setting\"\"\"     \n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","training_epochs = 10\n","save_term = int(training_epochs/5)\n","max_grad_norm = 10\n","lr = 1e-5\n","num_training_steps = len(train_dataset)*training_epochs\n","num_warmup_steps = len(train_dataset)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n","\n","save_path = path+'/model'"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":704,"status":"ok","timestamp":1685345643342,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"g3cogTR_fYIy"},"outputs":[],"source":["\"\"\"Input & Label Setting\"\"\"\n","best_vaild_fscore, best_test_fscore = 0, 0\n","best_vaild_fscore_macro, best_vaild_fscore_micro, best_test_fscore_macro, best_test_fscore_micro = 0, 0, 0, 0    \n","best_epoch = 0"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1685345643721,"user":{"displayName":"나상우","userId":"01186409037967778319"},"user_tz":-540},"id":"tvqYhnRvfacv"},"outputs":[],"source":["from tqdm import tqdm\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWhtsTqxe0VZ","outputId":"92664f62-6a10-429c-d2d3-ba59b59c750f"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]}],"source":["import time\n","\n","for epoch in tqdm(range(training_epochs)):\n","    start_time = time.time()  # Start time of the epoch\n","\n","    model.train() \n","    for i_batch, data in enumerate(train_dataloader):\n","        if i_batch > train_sample_num:\n","            print(i_batch, train_sample_num)\n","            break\n","        \n","        \"\"\"Prediction\"\"\"\n","        batch_input_tokens, batch_labels = data\n","        batch_input_tokens, batch_labels = batch_input_tokens.cuda(), batch_labels.cuda()\n","\n","        pred_logits = model(batch_input_tokens)\n","\n","        \"\"\"Loss calculation & training\"\"\"\n","        loss_val = CELoss(pred_logits, batch_labels)\n","        \n","        loss_val.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","        \n","        \n","    \"\"\"Valid & Test evaluation\"\"\"\n","    model.eval()\n","    val_acc, val_pred_list, val_label_list = _CalACC(model, valid_dataloader)\n","    \n","    val_pre, val_rec, val_fbeta, _ = precision_recall_fscore_support(val_label_list, val_pred_list, average='weighted')\n","\n","    \"\"\"Best Score & Model Save\"\"\"\n","    if val_fbeta > best_vaild_fscore:\n","        best_valid_fscore = val_fbeta\n","        \n","        test_acc, test_pred_list, test_label_list = _CalACC(model, test_dataloader)\n","        test_pre, test_rec, test_fbeta, _ = precision_recall_fscore_support(test_label_list, test_pred_list, average='weighted')                \n","        \n","        best_epoch = epoch\n","        _SaveModel(model, save_path)\n","\n","    print('Epoch: {}'.format(epoch))\n","    print('Devleopment ## accuracy: {}, precision: {}, recall: {}, fscore: {}'.format(val_acc, val_pre, val_rec, val_fbeta))\n","    print()\n","\n","print('Final Fscore ## test-accuracy: {}, test-fscore: {}, test_epoch: {}'.format(test_acc, test_fbeta, best_epoch))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
